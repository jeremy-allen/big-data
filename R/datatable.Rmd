---
title: "datatable_demo"
author: "Jeremy Allen"
date: "9/23/2021"L
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)

library(here)
library(imputeTS)
library(data.table)
#library(pins)

```

# Why Use data.table?

```{r data, include=FALSE}

# get state data from The New York Times github
states <- fread(
  input = "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv",
  key = c('state', 'date')
)

# get US national data from The New York Times github
us <- fread(
  input = "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv",
  key = 'date'
)

# get table of initial closure dates
#stay_at_home_table <- fread("https://raw.githubusercontent.com/jeremy-allen/covid-deaths/main/home_dates.csv")

```

```{r}

# we haven't loaded tidyverse yet, so let's do now
library(tidyverse)

# reminder
states

# for convenience let's have a dt and df for comparing
dt <- states
df <- as_tibble(states)


# in data.table what is dt[i,j,by]?
#  = take DT, subset/reorder rows using i, then calculate j, grouped by by

# i (think filtering by rows)
dt[state == "Georgia",]

# your turn! what happens here?
dt[1:3]
df[1:3]

# j (think doing work on columns)
dt[, max(deaths)]

# by (think grouping your work by categories of a variable)
dt[, .(max_deaths = max(deaths)), by = state]



# tidyverse equivalents

# i = filter
df %>% 
  filter(state == "Georgia")

# j = 
df %>% 
  pull(deaths) %>% 
  max()

# by = group_by and summarise
df %>% 
  group_by(state) %>% 
  max(deaths) # will error

df %>% 
  group_by(state) %>% 
  summarise(deaths = max(deaths))




#--- TOTAL DEATHS BY STATE ----

# tidyverse way

df %>% 
  group_by(state) %>% 
  arrange(state, date) %>% 
  summarise(deaths_total = last(deaths)) %>% 
  ungroup() %>% 
  arrange(desc(deaths_total))


# data.table way

setkey(dt, state, date) # makes an ordered index of values

dt[, .(deaths_total = data.table::last(deaths)), by = state][order(-deaths_total)]


# let's time them

tictoc::tic("tidyverse way")
df %>% 
  group_by(state) %>% 
  arrange(state, date) %>% 
  summarise(deaths_total = last(deaths)) %>% 
  ungroup() %>% 
  arrange(desc(deaths_total))
tictoc::toc()

tictoc::tic("data.table way")
setkey(dt, state, date)
dt[, .(deaths_total = data.table::last(deaths)), by = state][order(-deaths_total)]
tictoc::toc()


# if you read it in as a df and need to convert to data.table is it still faster?

tictoc::tic("data.table way")
dt <- as.data.table(df)
setkey(dt, state, date)
dt[, .(deaths_total = data.table::last(deaths)), by = state][order(-deaths_total)]
tictoc::toc()


# what if I like pipes, can data.table do that?

# data.table can chain operations

dt[, .(deaths_total = data.table::last(deaths)), by = state][order(-deaths_total)][deaths_total <= 100,]

# or you can put each on new line so long as the clsoing and opening brackets are together

dt[
  , .(deaths_total = data.table::last(deaths)), by = state
  ][
    order(-deaths_total)
  ][
    deaths_total <= 100,
  ]

# or you can use the pipe with .

dt[, .(deaths_total = data.table::last(deaths)), by = state] %>% 
  .[order(-deaths_total)] %>% 
  .[deaths_total <= 100]



#--- adding new columns in place ----


# data.table way
dt[, state_death_total := data.table::last(deaths), by = state]

# tidyverse way
df %>% 
  group_by(state) %>% 
  mutate(state_death_total = last(deaths))

```

```{r states, include=FALSE}

#---- prep states ----

# Get state names for ones with more than 19 deaths
# if you want the total per group, but the group entries are
# cumulative, then you only want the last entry per group
# .N as an index on .SD, will give you the last row, then by = state
# then filter for deaths 20 or more
# and keep only the state names
state_totals <- states[, .SD[.N], by = state]

over19 <- state_totals[deaths >= 20, state]

# states a user can choose from
states <- states[state %chin% over19,]
state_choices <- states[, unique(state)]

# make new columns to show new cases and new deaths
count_cols = c('cases', 'deaths')
states[ , paste0('new_', count_cols) := lapply(.SD, function(x) x - shift(x, n = 1L, type = "lag")),
        by = state, .SDcols = count_cols]

date_range <- states[, range(unique(date))]
names(date_range) <- c("first", "last")

# rolling averages for new cases and new deaths
states <- states[
  , `:=`(
    nc_avg = frollmean(new_cases, 7L, align = "right"),
    nd_avg = frollmean(new_deaths, 7L, align = "right")
  )
  , by = state
][
  , c("nc_avg", "nd_avg") := lapply(.SD, ceiling), .SDcols = c("nc_avg", "nd_avg")
]

# joining closure dates
states <- stay_at_home_table[
  states, on = "state" 
][
  , plot_label_end := "REOPENING"
][
  , plot_label_start := "CLOSING"
]

```

```{r us, include=FALSE}

#---- prep US ----

# add column for new deaths
us[ , paste0('new_', count_cols) := lapply(.SD, function(x) x - shift(x, n = 1L, type = "lag")), .SDcols = count_cols]

# add rolling means
us[, `:=`(nd_avg = frollmean(new_deaths, 7L, align = "right"),
          deaths_avg = frollmean(deaths, 7L, align = "right"))]
# fill NA with 0
setnafill(us, type = "const", fill = 0L, cols=c("deaths_avg","nd_avg"))
# round up and convert to integer
us[, `:=`(nd_avg = as.integer(ceiling(nd_avg)),
          deaths_avg = as.integer(ceiling(deaths_avg)))]

# format
us_cases <- us[, last(cases)] %>% 
  formatC(digits = 0, format = "d", big.mark = ",")

us_deaths <- us[, last(deaths)] %>% 
  formatC(digits = 0, format = "d", big.mark = ",")


stats_list <- list(
  data_pulled = paste(as.character(Sys.time()), "UTC"),
  us_cases = us_cases,
  us_deaths = us_deaths,
  date_range = date_range,
  state_choices = state_choices,
  state_totals = state_totals,
  closure_table = stay_at_home_table
)


```

```{r accumulate, include=FALSE}

# ---- state accumulated data ----

#state_dat <- states[state %in% input$state_picker,]
state_dat <- states
setnafill(state_dat, type = "const", fill = 0L, cols=c("new_deaths"))

# names of top states in order
#state_levels <- state_dat[, .(n = last(new_deaths)), by = state][order(-n)][, state] 

message("> adding rolling means")

# add rolling means
state_dat[, `:=`(nd_avg = frollmean(new_deaths, 7L, align = "right"),
                 deaths_avg = frollmean(deaths, 7L, align = "right")), by = state]
# fill NA with 0
setnafill(state_dat, type = "const", fill = 0L, cols=c("deaths_avg","nd_avg"))
# round up and convert to integer
state_dat[, `:=`(nd_avg = as.integer(ceiling(nd_avg)),
                 deaths_avg = as.integer(ceiling(deaths_avg)))]

# just each day after a state had at least 10 deaths
since10 <- state_dat[
  , days_since_10 := {
    date0 = date[which(deaths >= 10L)[1L]]
    if (is.na(date0)) NA_integer_ else date - date0
  }, by = state][days_since_10 >= 0, ][
    , !(c("fips", "cases", "new_cases"))
  ][ # change 0s to NA so we can impute them
    nd_avg == 0L, nd_avg := NA_integer_
  ][ # we impute them because 0s will crash our y axis log scale
    , nd_avg := as.integer(ceiling(imputeTS::na_kalman(nd_avg))), by = state
  ][
    , state := as.factor(state), by = state
  ]

message("> starting accumulate_by")

# define function that will be intermediate cumulative states for animation
accumulate_by <- function(states, var) {
  var <- lazyeval::f_eval(var, states)
  lvls <- plotly:::getLevels(var)
  dats <- lapply(seq_along(lvls), function(x) {
    cbind(states[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])
  })
  dplyr::bind_rows(dats)
}

# make list with each state its own element
since10 <- split(
  x = since10,
  by = "state"
)

since10 <- lapply(since10, as.data.frame)

# apply function to each data.table in the list
states_accumulated <- lapply(since10, accumulate_by, var = ~days_since_10)

# since10_accumulated <- as.data.frame(since10) %>% 
#   accumulate_by(var = ~days_since_10)

```
